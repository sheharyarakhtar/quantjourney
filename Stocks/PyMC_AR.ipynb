{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pymc as pm\n",
    "from pandas import Timedelta, date_range\n",
    "import arviz as az\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_seasonality(data, seasonality, amplitude, amplitude_noise = 1, noise = 1):\n",
    "    for i in range(len(data)):\n",
    "        amplitude = np.random.normal(amplitude, amplitude_noise)\n",
    "        data[i] = data[i] + amplitude*np.sin(2*np.pi*i/seasonality) + np.random.normal(0, noise)\n",
    "    return data\n",
    "\n",
    "\n",
    "def add_slope(data, intercept, intercept_noise, slope, slope_noise = 1, noise = 1):\n",
    "    for i in range(len(data)):\n",
    "        slope = np.random.normal(slope, slope_noise)\n",
    "        intercept = np.random.normal(intercept, intercept_noise)\n",
    "        if i == 0:\n",
    "            data[i] = data[i] + intercept + np.random.normal(0, noise)\n",
    "        else:\n",
    "            data[i] = data[i] + slope*i + np.random.normal(0, noise)\n",
    "    return data \n",
    "    # y_t = intercept + np.arange(len(data)) * slope + np.random.normal(0, intercept_noise, len(data))\n",
    "    # return y_t + ar1_data\n",
    "\n",
    "def generate_ar_process(coeffs, warmup=50, steps=150, intercept=10, noise=0.5, random=False, num_coeff = 0):\n",
    "    \"\"\"\n",
    "    Generate an autoregressive process based on provided coefficients.\n",
    "    \n",
    "    Parameters:\n",
    "    - coeffs: List of AR coefficients\n",
    "    - warmup: Number of warmup steps to discard\n",
    "    - steps: Number of steps to keep\n",
    "    - intercept: Baseline value\n",
    "    - noise: Standard deviation of random noise\n",
    "    - random: If True, generates random coefficients between -0.5 and 0.5\n",
    "    \n",
    "    Returns:\n",
    "    - ar_data: Generated time series data\n",
    "    \"\"\"\n",
    "    if random:\n",
    "        coeffs = np.random.uniform(-0.99, 0.99, num_coeff)\n",
    "        print(f\"Generated random coefficients: {coeffs}\")\n",
    "    \n",
    "    # Number of lags is determined by the length of coeffs\n",
    "    n_lags = len(coeffs)\n",
    "    \n",
    "    # Initialize array for the entire process\n",
    "    draws = np.zeros(warmup + steps)\n",
    "    \n",
    "    # Initialize first n_lags values to the intercept\n",
    "    draws[:n_lags] = intercept\n",
    "    \n",
    "    # Generate the AR process: each value depends on previous values\n",
    "    for step in range(n_lags, warmup + steps):\n",
    "        # Start with intercept\n",
    "        value = intercept\n",
    "        \n",
    "        # Add contribution from each lag\n",
    "        for i, coef in enumerate(coeffs):\n",
    "            value += coef * draws[step - i - 1]\n",
    "        \n",
    "        # Add random noise\n",
    "        value += np.random.normal(0, noise)\n",
    "        \n",
    "        draws[step] = value\n",
    "        \n",
    "    # Return only the non-warmup portion\n",
    "    return draws[warmup:]\n",
    "\n",
    "\n",
    "def add_seasonality(data, seasonality, amplitude, noise = 1):\n",
    "    y_t = amplitude * np.sin(2 * np.pi * np.arange(len(data)) / seasonality) + np.random.normal(0, noise, len(data))\n",
    "    return y_t + data\n",
    "\n",
    "\n",
    "# Generate the AR process\n",
    "\n",
    "\n",
    "slope_intercept = 2\n",
    "slope_intercept_noise = 0\n",
    "slope_coeff = 1\n",
    "slope_coeff_noise = 0.54\n",
    "\n",
    "\n",
    "warmup = 100\n",
    "steps = 300\n",
    "intercept = 10\n",
    "noise = 5\n",
    "coeffs = [-0.9, -0.7] \n",
    "num_coeff = len(coeffs)\n",
    "random = False\n",
    "\n",
    "\n",
    "seasonality = 12\n",
    "seasonality_amplitude = 120\n",
    "seasonality_amplitude_noise = 0\n",
    "seasonality_noise = 35\n",
    "ticker = 'AAPL'\n",
    "\n",
    "\n",
    "# ar1_data = generate_ar_process(coeffs, warmup, steps, intercept, noise, random=random, num_coeff = num_coeff)\n",
    "# ar1_data = add_slope(ar1_data, intercept = slope_intercept, intercept_noise = slope_intercept_noise, slope = slope_coeff, slope_noise = slope_coeff_noise, noise = 0)\n",
    "# ar1_data = add_seasonality(ar1_data, seasonality = seasonality, amplitude = seasonality_amplitude, noise = seasonality_noise)\n",
    "\n",
    "end_date = pd.to_datetime('2025-06-03')\n",
    "steps = 365*3\n",
    "start_date = end_date - pd.Timedelta(days=steps)\n",
    "\n",
    "ar1_data = yf.download(ticker, start=start_date, end=end_date, multi_level_index=False)\n",
    "ar1_data = ar1_data['Close'] - ar1_data['Open']\n",
    "\n",
    "# Create a figure to visualize the simulated time series\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "ax.set_title(f\"{ticker} Timeseries\", fontsize=15)\n",
    "# Create date range for x-axis\n",
    "date_range = pd.date_range(start=start_date, end=end_date, periods=len(ar1_data))\n",
    "ax.plot(date_range, ar1_data)  # Plot the data with dates on x-axis\n",
    "ax.tick_params(axis='x', rotation=45)  # Rotate date labels for better readability\n",
    "ax.set_xlabel('Date')  # Add x-axis label\n",
    "plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: [alpha, ar, beta, coefs, likelihood, sigma]\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [coefs, sigma, ar, alpha, beta]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/sheharyar/miniconda3/envs/pymc_env/lib/python3.13/site-packages/rich/live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/sheharyar/miniconda3/envs/pymc_env/lib/python3.13/site-packages/rich/live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 500 draw iterations (4_000 + 2_000 draws total) took 6 seconds.\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n",
      "Sampling: [likelihood]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/sheharyar/miniconda3/envs/pymc_env/lib/python3.13/site-packages/rich/live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/sheharyar/miniconda3/envs/pymc_env/lib/python3.13/site-packages/rich/live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pymc as pm\n",
    "import pytensor\n",
    "pytensor.config.cxx = '/usr/bin/clang++'\n",
    "\n",
    "\n",
    "arx = 3\n",
    "priors = {\n",
    "    \"coefs\": {\"mu\": np.zeros(arx + 1), \"sigma\": np.ones(arx + 1) * 10, \"size\": arx + 1},\n",
    "    \"sigma\": 8,\n",
    "    \"init\": {\"mu\": 9, \"sigma\": 0.1, \"size\": 1},\n",
    "    \"alpha\": {\"mu\": -0.3, \"sigma\": 0.1},\n",
    "    \"beta\": {\"mu\": 0.3, \"sigma\": 0.2},\n",
    "    \"seasonality\": {\"mu\": 0, \"sigma\": 0.1}\n",
    "}\n",
    "add_trend = True\n",
    "add_seasonality = False\n",
    "\n",
    "with pm.Model() as AR:\n",
    "    t_data = list(range(len(ar1_data)))\n",
    "    AR.add_coord(\"obs_id\", t_data)\n",
    "    \n",
    "    t = pm.Data(\"t\", t_data, dims=\"obs_id\")\n",
    "    y = pm.Data(\"y\", ar1_data, dims=\"obs_id\")\n",
    "    coefs = pm.Normal(\"coefs\", priors[\"coefs\"][\"mu\"], priors[\"coefs\"][\"sigma\"])\n",
    "    sigma = pm.HalfNormal(\"sigma\", priors[\"sigma\"])\n",
    "    init = pm.Normal.dist(\n",
    "        priors[\"init\"][\"mu\"], priors[\"init\"][\"sigma\"], size=priors[\"init\"][\"size\"]\n",
    "    )\n",
    "    \n",
    "    # Calculate steps explicitly to avoid shape attribute access\n",
    "    steps = len(t_data) - (priors[\"coefs\"][\"size\"] - 1)\n",
    "    \n",
    "    # Explicitly specify ar_order to fix the NotConstantValueError\n",
    "    ar1 = pm.AR(\n",
    "        \"ar\",\n",
    "        coefs,\n",
    "        sigma=sigma,\n",
    "        init_dist=init,\n",
    "        constant=True,\n",
    "        steps=steps,\n",
    "        ar_order=arx,  # Added explicit ar_order parameter\n",
    "        dims=\"obs_id\",\n",
    "    )\n",
    "    \n",
    "    alpha = pm.Normal(\"alpha\", priors[\"alpha\"][\"mu\"], priors[\"alpha\"][\"sigma\"])\n",
    "    \n",
    "    if add_trend:\n",
    "        beta = pm.Normal(\"beta\", priors[\"beta\"][\"mu\"], priors[\"beta\"][\"sigma\"])\n",
    "        trend = pm.Deterministic(\"trend\", alpha + beta * t, dims=\"obs_id\")\n",
    "        mu = ar1 + trend\n",
    "            \n",
    "        outcome = pm.Normal(\"likelihood\", mu=mu, sigma=sigma, observed=y, dims=\"obs_id\")\n",
    "    else:\n",
    "        outcome = pm.Normal(\"likelihood\", mu=ar1, sigma=sigma, observed=y, dims=\"obs_id\")\n",
    "        \n",
    "    idata_ar = pm.sample_prior_predictive()\n",
    "    idata_ar.extend(pm.sample(500, random_seed=100, target_accept=0.95))\n",
    "    idata_ar.extend(pm.sample_posterior_predictive(idata_ar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "\n",
    "\n",
    "def create_figure_layout(arx):\n",
    "    \"\"\"\n",
    "    Create a figure layout for AR model visualization.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    arx : int\n",
    "        The AR order\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    fig : matplotlib.figure.Figure\n",
    "        The figure object\n",
    "    axes : list\n",
    "        List of axes for parameter plots\n",
    "    ax_fit : matplotlib.axes.Axes\n",
    "        Axis for model fit plot\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Set up the figure for posterior plots\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "    # Calculate how many rows we need for parameters (max 3 per row)\n",
    "    param_rows = (arx + 2 + 2) // 3  # +2 for intercept and sigma, then ceiling division\n",
    "    # Create a GridSpec layout with param_rows + 1 rows (extra row for model fit)\n",
    "    gs = fig.add_gridspec(param_rows + 1, 3, height_ratios=[1] * param_rows + [1.5])\n",
    "\n",
    "    # Create axes: one for each coefficient plus sigma\n",
    "    axes = []\n",
    "    for i in range(arx + 2):\n",
    "        row = i // 3\n",
    "        col = i % 3\n",
    "        axes.append(fig.add_subplot(gs[row, col]))  # Parameters in rows of 3\n",
    "\n",
    "    # Add the model fit plot in the last row, spanning all columns\n",
    "    ax_fit = fig.add_subplot(gs[param_rows, :])  # bottom row spanning all columns for model fit\n",
    "    \n",
    "    return fig, axes, ax_fit\n",
    "\n",
    "def plot_ar_model_results(idata_ar, t_data, ar1_data, priors, add_trend_coeffs = False, arx=5, view_prev = None):\n",
    "    \"\"\"\n",
    "    Plot the posterior distributions and model fit for an AR model.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    idata_ar : InferenceData\n",
    "        The inference data containing posterior samples and posterior predictive samples\n",
    "    t_data : list or array\n",
    "        Time points for the observed data\n",
    "    ar1_data : list or array\n",
    "        The observed time series data\n",
    "    priors : dict\n",
    "        Dictionary containing prior information\n",
    "    arx : int, optional\n",
    "        The AR order (default=5)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    fig : matplotlib.figure.Figure\n",
    "        The figure object with all plots\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    if add_trend_coeffs:\n",
    "        arx += 4\n",
    "    fig, axes, ax_fit = create_figure_layout(arx)\n",
    "    plot_posterior_parameters(idata_ar, axes, arx, priors, add_trend_coeffs)\n",
    "    posterior_pred = plot_model_fit(idata_ar, t_data, ar1_data, ax_fit, view_prev = view_prev)\n",
    "    plt.tight_layout()\n",
    "    plt.show() \n",
    "    return fig, posterior_pred\n",
    "def plot_posterior_parameters(idata_ar, axes, arx, priors, add_trend_coeffs = False):\n",
    "    \"\"\"\n",
    "    Plot the posterior distributions of model parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    idata_ar : InferenceData\n",
    "        The inference data containing posterior samples\n",
    "    axes : list\n",
    "        List of matplotlib axes to plot on\n",
    "    arx : int\n",
    "        The AR order\n",
    "    priors : dict\n",
    "        Dictionary containing prior information\n",
    "    \"\"\"\n",
    "    az.plot_posterior(idata_ar, var_names=[\"coefs\"], coords={\"coefs_dim_0\": 0}, ax=axes[0])\n",
    "    axes[0].set_title(\"Intercept\")\n",
    "    for i in range(1, arx-1):\n",
    "        if i <= priors[\"coefs\"][\"size\"] - 1:  # Check if coefficient exists in the model\n",
    "            az.plot_posterior(idata_ar, var_names=[\"coefs\"], coords={\"coefs_dim_0\": i}, ax=axes[i])\n",
    "            axes[i].set_title(f\"AR({i}) Coefficient\")\n",
    "    # Plot trend coefficients (alpha and beta)\n",
    "    if add_trend_coeffs:\n",
    "        az.plot_posterior(idata_ar, var_names=[\"alpha\"], ax=axes[arx-1])\n",
    "        axes[arx-1].set_title(\"Alpha (Trend Intercept)\")\n",
    "        az.plot_posterior(idata_ar, var_names=[\"beta\"], ax=axes[arx])\n",
    "        axes[arx].set_title(\"Beta (Trend Slope)\")\n",
    "\n",
    "    az.plot_posterior(idata_ar, var_names=[\"sigma\"], ax=axes[arx+1])\n",
    "    axes[arx+1].set_title(\"Sigma\")\n",
    "    # Plot sigma\n",
    "\n",
    "def plot_model_fit(idata_ar, t_data, ar1_data, ax, view_prev = None):\n",
    "    \"\"\"\n",
    "    Plot the model fit against the data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    idata_ar : InferenceData\n",
    "        The inference data containing posterior predictive samples\n",
    "    t_data : list or array\n",
    "        Time points for the observed data\n",
    "    ar1_data : list or array\n",
    "        The observed time series data\n",
    "    ax : matplotlib.axes.Axes\n",
    "        The axis to plot on\n",
    "    \"\"\"\n",
    "    if not view_prev:\n",
    "        view_prev = len(t_data)\n",
    "    ax.plot(t_data[-view_prev:], ar1_data[-view_prev:], 'o', color='black', alpha=0.6, label='Observed data')\n",
    "    posterior_pred = idata_ar.posterior_predictive[\"likelihood\"].values\n",
    "    n_samples = 100\n",
    "    sample_idx = np.random.choice(posterior_pred.shape[0] * posterior_pred.shape[1], n_samples, replace=False)\n",
    "    for idx in sample_idx:\n",
    "        chain_idx, draw_idx = idx // posterior_pred.shape[1], idx % posterior_pred.shape[1]\n",
    "        ax.plot(t_data[-view_prev:], posterior_pred[chain_idx, draw_idx][-view_prev:], color='blue', alpha=0.1)\n",
    "\n",
    "    # # Plot the mean of the posterior predictive\n",
    "    posterior_pred_mean = posterior_pred.mean(axis=(0, 1))\n",
    "    ax.plot(t_data[-view_prev:], posterior_pred_mean[-view_prev:], color='red', linewidth=2, label='Posterior mean')\n",
    "\n",
    "    ax.set_title('NVDA Stock - Model Fit')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.legend()\n",
    "    return posterior_pred\n",
    "\n",
    "fig, posterior_pred = plot_ar_model_results(idata_ar, t_data, ar1_data, priors, arx=1, add_trend_coeffs = True, view_prev = 150);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(idata_ar, var_names=[\"coefs\"], combined=False, compact=False)\n",
    "az.plot_trace(idata_ar, var_names=[\"sigma\"], kind=\"rank_bars\", combined=False, compact=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_future_coordinates(model, data_length, prediction_length):\n",
    "    \"\"\"Set up coordinates for future predictions.\"\"\"\n",
    "    model.add_coords({\"obs_id_fut_1\": range(data_length - 1, prediction_length, 1)})\n",
    "    model.add_coords({\"obs_id_fut\": range(data_length, prediction_length, 1)})\n",
    "    return model\n",
    "\n",
    "def plot_observed_data(ax, t_data, ar1_data, view_prev):\n",
    "    \"\"\"Plot the observed data points.\"\"\"\n",
    "    ax.plot(t_data[-view_prev:], ar1_data[-view_prev:], '-o', color='black', alpha=0.6, label='Observed data')\n",
    "\n",
    "def plot_posterior_samples(ax, t_data, posterior_pred, view_prev, n_samples=100, alpha = 0.05):\n",
    "    \"\"\"Plot samples from the posterior distribution.\"\"\"\n",
    "    sample_idx = np.random.choice(posterior_pred.shape[0] * posterior_pred.shape[1], n_samples, replace=False)\n",
    "    for idx in sample_idx:\n",
    "        chain_idx, draw_idx = idx // posterior_pred.shape[1], idx % posterior_pred.shape[1]\n",
    "        ax.plot(t_data[-view_prev:], posterior_pred[chain_idx, draw_idx][-view_prev:], color='blue', alpha=alpha)\n",
    "\n",
    "def plot_posterior_mean(ax, t_data, posterior_pred, view_prev):\n",
    "    \"\"\"Plot the mean of the posterior predictive distribution.\"\"\"\n",
    "    posterior_pred_mean = posterior_pred.mean(axis=(0, 1))\n",
    "    ax.plot(t_data[-view_prev:], posterior_pred_mean[-view_prev:], color='red', linewidth=2, label='Posterior mean')\n",
    "\n",
    "def plot_future_samples(ax, future_predictions, t_future, n_samples=100, alpha = 0.05):\n",
    "    \"\"\"Plot samples of future predictions.\"\"\"\n",
    "    sample_idx = np.random.choice(future_predictions.shape[0] * future_predictions.shape[1], n_samples, replace=False)\n",
    "    future_pred_mean = future_predictions.mean(axis=(0, 1))\n",
    "    \n",
    "    # Calculate max distance for normalization\n",
    "    all_distances = []\n",
    "    for idx in sample_idx:\n",
    "        chain_idx, draw_idx = idx // future_predictions.shape[1], idx % future_predictions.shape[1]\n",
    "        sample = future_predictions[chain_idx, draw_idx]\n",
    "        distance = np.mean(np.abs(sample - future_pred_mean))\n",
    "        all_distances.append(distance)\n",
    "    \n",
    "    max_distance = max(all_distances) if all_distances else 1\n",
    "    \n",
    "    for idx in sample_idx:\n",
    "        chain_idx, draw_idx = idx // future_predictions.shape[1], idx % future_predictions.shape[1]\n",
    "        sample = future_predictions[chain_idx, draw_idx]\n",
    "        \n",
    "        # Calculate distance from mean (normalized)\n",
    "        distance = np.mean(np.abs(sample - future_pred_mean))\n",
    "        norm_distance = distance / max_distance if max_distance > 0 else 0\n",
    "        \n",
    "        # Create a gradient from yellowish (closest) to reddish (middle) to blueish (furthest)\n",
    "        if norm_distance < 0.5:\n",
    "            # Yellow to red gradient (0 to 0.5)\n",
    "            ratio = norm_distance * 2  # Scale to 0-1 range\n",
    "            color = (1, 1 - ratio, 0)  # Yellow (1,1,0) to Red (1,0,0)\n",
    "        else:\n",
    "            # Red to blue gradient (0.5 to 1)\n",
    "            ratio = (norm_distance - 0.5) * 2  # Scale to 0-1 range\n",
    "            color = (1 - ratio, 0, ratio)  # Red (1,0,0) to Blue (0,0,1)\n",
    "        \n",
    "        ax.plot(t_future, sample, color=color, alpha=alpha)\n",
    "\n",
    "def plot_future_mean(ax, future_predictions, t_future):\n",
    "    \"\"\"Plot the mean of future predictions.\"\"\"\n",
    "    future_pred_mean = future_predictions.mean(axis=(0, 1))\n",
    "    ax.plot(t_future, future_pred_mean, color='green', linewidth=2, label='Future predictions (mean)', marker='o')\n",
    "\n",
    "\n",
    "def setup_plot_labels(ax, arx):\n",
    "    \"\"\"Set up the plot title, labels, and legend.\"\"\"\n",
    "    # Fix: plt is a module, not an Axes object. We need to use the ax parameter instead.\n",
    "    ax.set_title(f'AR({arx}) Model Predictions')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.legend()\n",
    "\n",
    "def predict_future_points(AR, ar1, ar1_data, coefs, sigma, steps, idata_ar, n=10):\n",
    "    \"\"\"\n",
    "    Predict future points in the time series using the AR model.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    AR : PyMC model\n",
    "        The AR model\n",
    "    ar1 : PyMC variable\n",
    "        The AR process variable\n",
    "    ar1_data : array\n",
    "        The observed data\n",
    "    coefs : PyMC variable\n",
    "        The AR coefficients\n",
    "    sigma : PyMC variable\n",
    "        The noise standard deviation\n",
    "    steps : int\n",
    "        Number of steps in the original data\n",
    "    idata_ar : InferenceData\n",
    "        The inference data from model fitting\n",
    "    n : int, optional\n",
    "        Number of future points to predict, default is 10\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (future_predictions, t_future)\n",
    "    \"\"\"\n",
    "    prediction_length = steps + n\n",
    "    view_prev = n*3\n",
    "    n_samples = 100\n",
    "    \n",
    "    # Create a new figure for the predictions\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Try to make predictions, handling the case where variables might already exist\n",
    "    try:\n",
    "        with AR:\n",
    "            # First check if coordinates already exist and remove them to avoid duplicates\n",
    "            if \"obs_id_fut_1\" in AR.coords:\n",
    "                AR.coords.pop(\"obs_id_fut_1\")\n",
    "            if \"obs_id_fut\" in AR.coords:\n",
    "                AR.coords.pop(\"obs_id_fut\")\n",
    "                \n",
    "            # Setup coordinates for future predictions\n",
    "            AR.add_coords({\"obs_id_fut_1\": range(ar1_data.shape[0] - 1, prediction_length, 1)})\n",
    "            AR.add_coords({\"obs_id_fut\": range(ar1_data.shape[0], prediction_length, 1)})\n",
    "            \n",
    "            # Handle t_fut data variable\n",
    "            try:\n",
    "                # Try to remove existing t_fut if it exists\n",
    "                if 't_fut' in AR.named_vars:\n",
    "                    AR.named_vars.pop('t_fut')\n",
    "                t_fut = pm.Data(\"t_fut\", list(range(ar1_data.shape[0], prediction_length, 1)))\n",
    "            except Exception as e:\n",
    "                print(f\"Error handling t_fut: {e}\")\n",
    "                # Fallback to direct assignment\n",
    "                t_fut = list(range(ar1_data.shape[0], prediction_length, 1))\n",
    "                \n",
    "            # Create the future AR model\n",
    "            try:\n",
    "                # Remove existing ar1_fut if it exists\n",
    "                if 'ar1_fut' in AR.named_vars:\n",
    "                    AR.named_vars.pop('ar1_fut')\n",
    "                ar1_fut = pm.AR(\n",
    "                    \"ar1_fut\",\n",
    "                    init_dist=pm.DiracDelta.dist(ar1[..., -1]),\n",
    "                    rho=coefs,\n",
    "                    sigma=sigma,\n",
    "                    constant=True,\n",
    "                    dims=\"obs_id_fut_1\",\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating ar1_fut: {e}\")\n",
    "                ar1_fut = AR.named_vars.get('ar1_fut')\n",
    "           \n",
    "            # Handle trend and seasonality components\n",
    "            if 'add_trend' in globals() and add_trend and 'add_seasonality' not in globals():\n",
    "                print('Adding trend component')\n",
    "                if 'trend_fut' in AR.named_vars:\n",
    "                    AR.named_vars.pop('trend_fut')\n",
    "                trend = pm.Deterministic(\"trend_fut\", alpha + beta * t_fut, dims=\"obs_id_fut\")\n",
    "                mu = ar1_fut[1:] + trend\n",
    "                if 'yhat_fut' in AR.named_vars:\n",
    "                    AR.named_vars.pop('yhat_fut')\n",
    "                yhat_fut = pm.Normal(\"yhat_fut\", mu=mu, sigma=sigma, dims=\"obs_id_fut\")\n",
    "            elif 'add_trend' in globals() and 'add_seasonality' in globals() and add_trend and add_seasonality:\n",
    "                print('Adding trend and seasonality components')\n",
    "                if 'trend_fut' in AR.named_vars:\n",
    "                    AR.named_vars.pop('trend_fut')\n",
    "                if 'seasonality_fut' in AR.named_vars:\n",
    "                    AR.named_vars.pop('seasonality_fut')\n",
    "                trend = pm.Deterministic(\"trend_fut\", alpha + beta * t_fut, dims=\"obs_id_fut\")\n",
    "                seasonality = pm.Deterministic(\"seasonality_fut\", seasonality, dims=\"obs_id_fut\")\n",
    "                mu = ar1_fut[1:] + trend + seasonality\n",
    "                if 'yhat_fut' in AR.named_vars:\n",
    "                    AR.named_vars.pop('yhat_fut')\n",
    "                yhat_fut = pm.Normal(\"yhat_fut\", mu=mu, sigma=sigma, dims=\"obs_id_fut\")\n",
    "            else:\n",
    "                print('Using basic AR model without trend or seasonality')\n",
    "                if 'yhat_fut' in AR.named_vars:\n",
    "                    AR.named_vars.pop('yhat_fut')\n",
    "                yhat_fut = pm.Normal(\"yhat_fut\", mu=ar1_fut[1:], sigma=sigma, dims=\"obs_id_fut\")\n",
    "                \n",
    "            # Sample from the posterior predictive distribution\n",
    "            idata_preds = pm.sample_posterior_predictive(\n",
    "                idata_ar, var_names=[\"likelihood\", \"yhat_fut\"], predictions=True, random_seed=100\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {e}\")\n",
    "        # Try a more robust approach if the first attempt fails\n",
    "        try:\n",
    "            # Create a new model for predictions to avoid conflicts\n",
    "            with pm.Model() as pred_model:\n",
    "                # Set up coordinates\n",
    "                pred_model.add_coords({\"obs_id_fut_1\": range(ar1_data.shape[0] - 1, prediction_length, 1)})\n",
    "                pred_model.add_coords({\"obs_id_fut\": range(ar1_data.shape[0], prediction_length, 1)})\n",
    "                \n",
    "                # Get posterior samples\n",
    "                posterior_samples = idata_ar.posterior\n",
    "                \n",
    "                # Extract parameters from posterior\n",
    "                coefs_samples = posterior_samples.coefs.values\n",
    "                sigma_samples = posterior_samples.sigma.values\n",
    "                \n",
    "                # Create deterministic variables for predictions\n",
    "                ar_init = pm.ConstantData(\"ar_init\", ar1[..., -1].eval())\n",
    "                \n",
    "                # Create AR process\n",
    "                ar1_fut = pm.AR(\n",
    "                    \"ar1_fut\",\n",
    "                    init_dist=pm.DiracDelta.dist(ar_init),\n",
    "                    rho=coefs_samples.mean(axis=(0, 1)),  # Use mean of posterior\n",
    "                    sigma=sigma_samples.mean(axis=(0, 1)),  # Use mean of posterior\n",
    "                    constant=True,\n",
    "                    dims=\"obs_id_fut_1\",\n",
    "                )\n",
    "                \n",
    "                # Create predictions\n",
    "                yhat_fut = pm.Normal(\"yhat_fut\", mu=ar1_fut[1:], sigma=sigma_samples.mean(axis=(0, 1)), dims=\"obs_id_fut\")\n",
    "                \n",
    "                # Sample from the posterior predictive\n",
    "                idata_preds = pm.sample_posterior_predictive(\n",
    "                    posterior_samples, var_names=[\"yhat_fut\"], predictions=True, random_seed=100\n",
    "                )\n",
    "        except Exception as nested_e:\n",
    "            print(f\"Fallback prediction approach also failed: {nested_e}\")\n",
    "            raise RuntimeError(f\"Could not generate predictions: {e}\\nNested error: {nested_e}\")\n",
    "    \n",
    "    # Extract future predictions\n",
    "    future_predictions = idata_preds.predictions[\"yhat_fut\"].values\n",
    "    t_future = np.arange(ar1_data.shape[0], prediction_length)\n",
    "    \n",
    "    return future_predictions, t_future\n",
    "\n",
    "# Predict the next 10 points in the time series\n",
    "n = 15\n",
    "future_predictions, t_future = predict_future_points(AR = AR, ar1 = ar1, ar1_data = ar1_data, coefs = coefs, sigma = sigma, steps = len(ar1_data), idata_ar = idata_ar, n=n)\n",
    "view_prev = n*4\n",
    "n_samples = 500\n",
    "alpha = 0.05\n",
    "\n",
    "end_date = pd.to_datetime('2025-05-27')\n",
    "start_date = end_date - pd.Timedelta(days=steps)\n",
    "forecast_start = end_date + pd.Timedelta(days=0)\n",
    "forecast_end = end_date + pd.Timedelta(days=n-1)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# # Plot the data and predictions\n",
    "from pandas import date_range\n",
    "dr = date_range(start_date, end_date)\n",
    "fr = date_range(forecast_start, forecast_end)\n",
    "plot_posterior_samples(ax, dr, posterior_pred, view_prev, n_samples, alpha = alpha)\n",
    "# plot_posterior_mean(ax, t_data, posterior_pred, view_prev)\n",
    "plot_future_samples(ax, future_predictions, fr, n_samples, alpha = alpha)\n",
    "plot_future_mean(ax, future_predictions, fr)\n",
    "ax.axvline(x=min(fr), color='red', linestyle='--', alpha=0.5)\n",
    "plot_observed_data(ax, dr, ar1_data, view_prev)\n",
    "setup_plot_labels(ax, arx)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
